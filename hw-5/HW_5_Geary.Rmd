---
title: "HW_5_Geary"
author: "Marion Geary"
date: "2/15/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

```{r}
library(tidymodels)
setwd("/Users/Marion/Desktop/math386/hw/hw-4")
load('rad.Rdata')
```

## Exercise 1

```{r}
rad <- rad %>% mutate(Sex = as.factor(Sex))

knn_model <- nearest_neighbor(neighbors = 5, weight_func = "epanechnikov", dist_power = 2, mode = "classification") %>% set_engine("kknn") %>% set_mode("classification")

set.seed(12)
rad_split <- rad %>%
  initial_split(prop = .8)
rad_test <- testing(rad_split)
rad_train <- training(rad_split)

rad_recipe <- recipe(BinaryDiagnosis ~ ., data = rad) %>%
  step_dummy(Sex) %>%
  step_normalize(all_predictors())

rad_wkflow <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(rad_recipe)

set.seed(12)
rad_folds <- vfold_cv(rad_train, v = 10, repeats = 5)
```

```{r}
my_metrics <- metric_set(sens, yardstick::spec, accuracy)

rad_pred <- control_resamples(save_pred = TRUE)

set.seed(12)
rad_res <- rad_wkflow %>% fit_resamples(resamples = rad_folds, control = rad_pred, metrics = my_metrics)
```

## Exercise 2

```{r}
collect_metrics(rad_res, event_level = "second")
```

Compared to HW 4, all metrics are higher for this resampled model. The `accuracy` has improved the most, from 0.475 to 0.606. The sensitivity improved from 0.542 to 0.556. Specificity increased from 0.375 to 0.651. These show how resampling improves the model.

## Exercise 3

```{r}
ggplot(collect_metrics(rad_res, summarize = F) %>%
         filter(.metric == "sens"), aes(x = .estimate)) + geom_histogram(fill = "red") + theme_classic() + labs(x = "Estimated Sensitivity", y = "Count", title = "Estimated Sensitivity")

ggplot(collect_metrics(rad_res, summarize = F) %>% 
         filter(.metric == "spec"), aes(x = .estimate)) + geom_histogram(fill = "blue") + theme_classic() + labs(x = "Estimated Specificity", y = "Count", title = "Estimated Specificity")

ggplot(collect_metrics(rad_res, summarize = F) %>%
         filter(.metric == "accuracy"), aes(x = .estimate)) + geom_histogram(fill = "green") + theme_classic() + labs(x = "Estimated Accuracy", y = "Count", title = "Estimated Accuracy")
```

The estimated sensitivity graph shows that the sensitiviy has a roughly normal distribution centered around the mean, and a range from 0 to 1. The estimated specificity is semi-normal, with the most values between 0.6 and 0.8. The distribution has a smaller standard deviation, with no values below 0.3. The estimated accuracy graph has a roughly normal distribution with most of the values falling close to the mean. The values range from 0 to 1, but few folds have those extreme values.

## Exercise 4

```{r}
k_grid <- tibble(neighbors = seq(2, 20, by = 2))

knn_model <- nearest_neighbor(neighbors = tune(), weight_func = "epanechnikov", dist_power = 2, mode = "classification") %>% set_engine("kknn")

rad_wkflow <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(rad_recipe)

rad_res_2 <- rad_wkflow %>% tune_grid(resamples = rad_folds, grid = k_grid, metrics = my_metrics)

collect_metrics(rad_res_2, event_level = "second")
show_best(rad_res_2, metric = "spec")
show_best(rad_res_2, metric = "sens")
show_best(rad_res_2, metric = "accuracy")

autoplot(rad_res_2)

all_tun_res <- collect_metrics(rad_res_2, event_level = "second", summarize = F) %>% mutate(neighbors = factor(neighbors))

ggplot(all_tun_res) +
  geom_boxplot(aes(x = neighbors, y = .estimate, color = .metric)) +
  labs(x = "# Nearest Neighbors", y = "Mean Performance Value", main = "Resampling Estimates for Tuning") + facet_wrap(~.metric)

## pick k = 6 because it is the highest for all metrics

final_rad_wkflow <- rad_wkflow %>%
  finalize_workflow(list(neighbors = 6))

final_fit <- final_rad_wkflow %>% fit(data = rad_train)

final_rad_aug <- augment(final_fit, new_data = rad_test)

my_metrics(final_rad_aug, truth = BinaryDiagnosis, estimate = .pred_class, event_level = "second")
```

For the final model, I chose `k = 6` because in the tuning results, 6 was in the top 5 values for all 3 metrics. While it was not the highest for any individual metric, it was the most consistently high performing choice for `k`, making it the best choice for the final model.

## Exercise 5

```{r}
ggplot(collect_metrics(rad_res_2, summarize = F, event_level = "second") %>%
         filter(.metric == "sens") %>% filter(neighbors == 6), aes(x = .estimate)) + geom_histogram(fill = "red") + theme_classic() + labs(x = "Estimated Sensitivity", y = "Count", title = "Estimated Sensitivity")

ggplot(collect_metrics(rad_res_2, summarize = F, event_level = "second") %>% 
         filter(.metric == "spec") %>% filter(neighbors == 6), aes(x = .estimate)) + geom_histogram(fill = "blue") + theme_classic() + labs(x = "Estimated Specificity", y = "Count", title = "Estimated Specificity")

ggplot(collect_metrics(rad_res_2, summarize = F, event_level = "second") %>%
         filter(.metric == "accuracy") %>% filter(neighbors == 6), aes(x = .estimate)) + geom_histogram(fill = "green") + theme_classic() + labs(x = "Estimated Accuracy", y = "Count", title = "Estimated Accuracy")
```

The estimated sensitivity is pretty normal, with a large standard deviation. We see that the values are centered around the mean. The estimated specificity is also fairly normal, although the standard deviation is a bit smaller. The values from 0.2 to 1 rather than from 0 to 1. The estimated accuracy has a peak around the mean, with few values outside the range from 0.5 to 0.75. These distributions are very similar to the first set of distributions that did not include tuning.
